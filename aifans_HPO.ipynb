{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/bbll-uuee/e-shopping-recommendation.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7lzoCShc0DX",
        "outputId": "ba15e52b-7043-4e2d-ddd6-fd8fa29741e5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'e-shopping-recommendation' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kNIFdh1pTb7",
        "outputId": "c8adedf3-534d-4390-929d-b631491fdeb2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd e-shopping-recommendation/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pC64vGEppcby",
        "outputId": "09afa88f-606e-487c-8b72-99a57880131a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/e-shopping-recommendation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjflA3uApd5H",
        "outputId": "4df84bcb-da30-4e5f-8b82-2bd254d65bd2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Amazon.zip                          README.md\n",
            " cleaned_amazon_data_final.csv.zip   requirements.txt\n",
            "'cleaned data.zip'                   step1_dataset_artifact.py\n",
            " final_model.py                      step2_data_preprocessing.py\n",
            " main.py                             step3_train_model.py\n",
            " pipeline_from_tasks.py              task_hpo.py\n",
            "'POC code'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install clearml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SLF4H71CBqW",
        "outputId": "2505f6b7-2284-4eb0-9132-fffeb010199f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: clearml in /usr/local/lib/python3.11/dist-packages (1.10.4)\n",
            "Requirement already satisfied: attrs>=18.0 in /usr/local/lib/python3.11/dist-packages (from clearml) (25.3.0)\n",
            "Requirement already satisfied: furl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from clearml) (2.1.4)\n",
            "Requirement already satisfied: jsonschema>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from clearml) (4.23.0)\n",
            "Requirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.11/dist-packages (from clearml) (1.24.3)\n",
            "Requirement already satisfied: pathlib2>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from clearml) (2.3.7.post1)\n",
            "Requirement already satisfied: Pillow>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from clearml) (11.2.1)\n",
            "Requirement already satisfied: psutil>=3.4.2 in /usr/local/lib/python3.11/dist-packages (from clearml) (5.9.5)\n",
            "Requirement already satisfied: pyparsing>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from clearml) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.11/dist-packages (from clearml) (2.9.0.post0)\n",
            "Requirement already satisfied: PyYAML>=3.12 in /usr/local/lib/python3.11/dist-packages (from clearml) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.11/dist-packages (from clearml) (2.32.3)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from clearml) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from clearml) (2.4.0)\n",
            "Requirement already satisfied: pyjwt<2.5.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from clearml) (2.4.0)\n",
            "Requirement already satisfied: orderedmultidict>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from furl>=2.0.0->clearml) (1.0.1)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6.0->clearml) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6.0->clearml) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6.0->clearml) (0.24.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20.0->clearml) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20.0->clearml) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20.0->clearml) (2025.4.26)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from referencing>=0.28.4->jsonschema>=2.6.0->clearml) (4.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!clearml-init"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeIQ9XzvC1vp",
        "outputId": "936948bd-455e-4e22-9b19-12e1e5b86612"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ClearML SDK setup process\n",
            "Configuration file already exists: /root/clearml.conf\n",
            "Leaving setup, feel free to edit the configuration file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r /content/e-shopping-recommendation/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hD3qGEJ8zVeI",
        "outputId": "5e7d3e75-7754-413c-9556-ea91f6dcd14e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: clearml==1.10.4 in /usr/local/lib/python3.11/dist-packages (from -r /content/e-shopping-recommendation/requirements.txt (line 1)) (1.10.4)\n",
            "Requirement already satisfied: matplotlib==3.7.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/e-shopping-recommendation/requirements.txt (line 2)) (3.7.1)\n",
            "Requirement already satisfied: numpy==1.24.3 in /usr/local/lib/python3.11/dist-packages (from -r /content/e-shopping-recommendation/requirements.txt (line 3)) (1.24.3)\n",
            "Requirement already satisfied: pandas==1.5.3 in /usr/local/lib/python3.11/dist-packages (from -r /content/e-shopping-recommendation/requirements.txt (line 4)) (1.5.3)\n",
            "Requirement already satisfied: scikit_learn==1.4.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/e-shopping-recommendation/requirements.txt (line 5)) (1.4.2)\n",
            "Requirement already satisfied: torch==2.1.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/e-shopping-recommendation/requirements.txt (line 6)) (2.1.2)\n",
            "Requirement already satisfied: optuna==4.3.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/e-shopping-recommendation/requirements.txt (line 7)) (4.3.0)\n",
            "Requirement already satisfied: tensorflow==2.13.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/e-shopping-recommendation/requirements.txt (line 8)) (2.13.0)\n",
            "Requirement already satisfied: attrs>=18.0 in /usr/local/lib/python3.11/dist-packages (from clearml==1.10.4->-r /content/e-shopping-recommendation/requirements.txt (line 1)) (25.3.0)\n",
            "Requirement already satisfied: furl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from clearml==1.10.4->-r /content/e-shopping-recommendation/requirements.txt (line 1)) (2.1.4)\n",
            "Requirement already satisfied: jsonschema>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from clearml==1.10.4->-r /content/e-shopping-recommendation/requirements.txt (line 1)) (4.23.0)\n",
            "Requirement already satisfied: pathlib2>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from clearml==1.10.4->-r /content/e-shopping-recommendation/requirements.txt (line 1)) (2.3.7.post1)\n",
            "Requirement already satisfied: Pillow>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from clearml==1.10.4->-r /content/e-shopping-recommendation/requirements.txt (line 1)) (11.2.1)\n",
            "Requirement already satisfied: psutil>=3.4.2 in /usr/local/lib/python3.11/dist-packages (from clearml==1.10.4->-r /content/e-shopping-recommendation/requirements.txt (line 1)) (5.9.5)\n",
            "Requirement already satisfied: pyparsing>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from clearml==1.10.4->-r /content/e-shopping-recommendation/requirements.txt (line 1)) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.11/dist-packages (from clearml==1.10.4->-r /content/e-shopping-recommendation/requirements.txt (line 1)) (2.9.0.post0)\n",
            "Requirement already satisfied: PyYAML>=3.12 in /usr/local/lib/python3.11/dist-packages (from clearml==1.10.4->-r /content/e-shopping-recommendation/requirements.txt (line 1)) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.11/dist-packages (from clearml==1.10.4->-r /content/e-shopping-recommendation/requirements.txt (line 1)) (2.32.3)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from clearml==1.10.4->-r /content/e-shopping-recommendation/requirements.txt (line 1)) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from clearml==1.10.4->-r /content/e-shopping-recommendation/requirements.txt (line 1)) (2.4.0)\n",
            "Requirement already satisfied: pyjwt<2.5.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from clearml==1.10.4->-r /content/e-shopping-recommendation/requirements.txt (line 1)) (2.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.1->-r /content/e-shopping-recommendation/requirements.txt (line 2)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.1->-r /content/e-shopping-recommendation/requirements.txt (line 2)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.1->-r /content/e-shopping-recommendation/requirements.txt (line 2)) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.1->-r /content/e-shopping-recommendation/requirements.txt (line 2)) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.1->-r /content/e-shopping-recommendation/requirements.txt (line 2)) (24.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas==1.5.3->-r /content/e-shopping-recommendation/requirements.txt (line 4)) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit_learn==1.4.2->-r /content/e-shopping-recommendation/requirements.txt (line 5)) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit_learn==1.4.2->-r /content/e-shopping-recommendation/requirements.txt (line 5)) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit_learn==1.4.2->-r /content/e-shopping-recommendation/requirements.txt (line 5)) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2->-r /content/e-shopping-recommendation/requirements.txt (line 6)) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2->-r /content/e-shopping-recommendation/requirements.txt (line 6)) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2->-r /content/e-shopping-recommendation/requirements.txt (line 6)) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2->-r /content/e-shopping-recommendation/requirements.txt (line 6)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2->-r /content/e-shopping-recommendation/requirements.txt (line 6)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2->-r /content/e-shopping-recommendation/requirements.txt (line 6)) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2->-r /content/e-shopping-recommendation/requirements.txt (line 6)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2->-r /content/e-shopping-recommendation/requirements.txt (line 6)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2->-r /content/e-shopping-recommendation/requirements.txt (line 6)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2->-r /content/e-shopping-recommendation/requirements.txt (line 6)) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2->-r /content/e-shopping-recommendation/requirements.txt (line 6)) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2->-r /content/e-shopping-recommendation/requirements.txt (line 6)) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2->-r /content/e-shopping-recommendation/requirements.txt (line 6)) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2->-r /content/e-shopping-recommendation/requirements.txt (line 6)) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2->-r /content/e-shopping-recommendation/requirements.txt (line 6)) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2->-r /content/e-shopping-recommendation/requirements.txt (line 6)) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2->-r /content/e-shopping-recommendation/requirements.txt (line 6)) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2->-r /content/e-shopping-recommendation/requirements.txt (line 6)) (2.1.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna==4.3.0->-r /content/e-shopping-recommendation/requirements.txt (line 7)) (1.14.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna==4.3.0->-r /content/e-shopping-recommendation/requirements.txt (line 7)) (6.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna==4.3.0->-r /content/e-shopping-recommendation/requirements.txt (line 7)) (2.0.24)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna==4.3.0->-r /content/e-shopping-recommendation/requirements.txt (line 7)) (4.67.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13.0->-r /content/e-shopping-recommendation/requirements.txt (line 8)) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13.0->-r /content/e-shopping-recommendation/requirements.txt (line 8)) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13.0->-r /content/e-shopping-recommendation/requirements.txt (line 8)) (25.2.10)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13.0->-r /content/e-shopping-recommendation/requirements.txt (line 8)) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13.0->-r /content/e-shopping-recommendation/requirements.txt (line 8)) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13.0->-r /content/e-shopping-recommendation/requirements.txt (line 8)) (1.71.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13.0->-r /content/e-shopping-recommendation/requirements.txt (line 8)) (3.13.0)\n",
            "Requirement already satisfied: keras<2.14,>=2.13.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13.0->-r /content/e-shopping-recommendation/requirements.txt (line 8)) (2.13.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13.0->-r /content/e-shopping-recommendation/requirements.txt (line 8)) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13.0->-r /content/e-shopping-recommendation/requirements.txt (line 8)) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13.0->-r /content/e-shopping-recommendation/requirements.txt (line 8)) (4.25.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13.0->-r /content/e-shopping-recommendation/requirements.txt (line 8)) (75.2.0)\n",
            "Requirement already satisfied: tensorboard<2.14,>=2.13 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13.0->-r /content/e-shopping-recommendation/requirements.txt (line 8)) (2.13.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13.0->-r /content/e-shopping-recommendation/requirements.txt (line 8)) (2.13.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13.0->-r /content/e-shopping-recommendation/requirements.txt (line 8)) (3.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13.0->-r /content/e-shopping-recommendation/requirements.txt (line 8)) (1.17.2)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13.0->-r /content/e-shopping-recommendation/requirements.txt (line 8)) (0.37.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.2->-r /content/e-shopping-recommendation/requirements.txt (line 6)) (12.5.82)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna==4.3.0->-r /content/e-shopping-recommendation/requirements.txt (line 7)) (1.1.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.13.0->-r /content/e-shopping-recommendation/requirements.txt (line 8)) (0.45.1)\n",
            "Requirement already satisfied: orderedmultidict>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from furl>=2.0.0->clearml==1.10.4->-r /content/e-shopping-recommendation/requirements.txt (line 1)) (1.0.1)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6.0->clearml==1.10.4->-r /content/e-shopping-recommendation/requirements.txt (line 1)) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6.0->clearml==1.10.4->-r /content/e-shopping-recommendation/requirements.txt (line 1)) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6.0->clearml==1.10.4->-r /content/e-shopping-recommendation/requirements.txt (line 1)) (0.24.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20.0->clearml==1.10.4->-r /content/e-shopping-recommendation/requirements.txt (line 1)) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20.0->clearml==1.10.4->-r /content/e-shopping-recommendation/requirements.txt (line 1)) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20.0->clearml==1.10.4->-r /content/e-shopping-recommendation/requirements.txt (line 1)) (2025.4.26)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna==4.3.0->-r /content/e-shopping-recommendation/requirements.txt (line 7)) (3.2.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0->-r /content/e-shopping-recommendation/requirements.txt (line 8)) (2.38.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0->-r /content/e-shopping-recommendation/requirements.txt (line 8)) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0->-r /content/e-shopping-recommendation/requirements.txt (line 8)) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0->-r /content/e-shopping-recommendation/requirements.txt (line 8)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0->-r /content/e-shopping-recommendation/requirements.txt (line 8)) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.1.2->-r /content/e-shopping-recommendation/requirements.txt (line 6)) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.1.2->-r /content/e-shopping-recommendation/requirements.txt (line 6)) (1.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0->-r /content/e-shopping-recommendation/requirements.txt (line 8)) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0->-r /content/e-shopping-recommendation/requirements.txt (line 8)) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0->-r /content/e-shopping-recommendation/requirements.txt (line 8)) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13.0->-r /content/e-shopping-recommendation/requirements.txt (line 8)) (2.0.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0->-r /content/e-shopping-recommendation/requirements.txt (line 8)) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13.0->-r /content/e-shopping-recommendation/requirements.txt (line 8)) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/e-shopping-recommendation/step1_dataset_artifact.py"
      ],
      "metadata": {
        "id": "CvovePnyp7SS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cf06908-9097-43a4-cfe3-c1e7d7781747"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ClearML Task: created new task id=6c12c89305ba4a558fc25ffbe37c1287\n",
            "CLEARML new package available: UPGRADE to v2.0.0 is recommended!\n",
            "Release Notes:\n",
            "### New Features\n",
            "\n",
            "- Clean up exception handeling in cleanup_service.py (#1387, thanks @PixelWelt!)\n",
            "- Add support for `clearml-task` command line options `--force-no-requirements`, `--skip-repo-detection` and `--skip-python-env-install`\n",
            "- Allow calling the same pipeline step multiple times with inputs that originate from tasks/controller\n",
            "- Add `Task.upload_artifact()` argument `sort_keys` to allow disabling sorting yaml/json keys when uploading artifacts\n",
            "- Add python annotations to all methods\n",
            "- Update `pyjwt` constraint version\n",
            "\n",
            "\n",
            "### Bug Fixes\n",
            "\n",
            "- Fix local file uploads without scheme (#1326, thanks @d-vignesh!)\n",
            "- Fix argument order mismatch in `PipelineController` (#1407, thanks @rashboldb!)\n",
            "- Fix `_logger` property might be `None` in Session (#1412, thanks @AH-Merii!)\n",
            "- Fix unhandled `None` value in project IDs when listing all datasets (#1413, thanks @AH-Merii!)\n",
            "- Fix typo in config exception string (#1418, thanks @AH-Merii!)\n",
            "- Fix experiments are created twice during HPO (#644)\n",
            "- Fix `clearml-task`-run HPO breaks up (#1151)\n",
            "- Fix oversized event reports cause subsequent events to be lost (#1316)\n",
            "- Fix downloading datasets with multiple parents might not work (#1398)\n",
            "- Fix GPU reporting fails to detect GPU when the `NVIDIA_VISIBLE_DEVICES` env var contains a directory reference\n",
            "- Fix `verify` configuration option for S3 storage (boto3) is not used when testing buckets\n",
            "- Fix `PipelineDecorator.component()` ignores `*args` and crashes with `**kwargs`\n",
            "- Fix Pipelines ran via `clearml-task` do not appear in the UI\n",
            "- Fix task log URL print for API v2.31 should show `\"/tasks/{}/output/log\"`\n",
            "- Fix `tqdm` upload/download reporting, remove warning\n",
            "- Fix pipeline from CLI with no args fails\n",
            "- Fix `pillow` constraint for Python<=3.7\n",
            "- Fix `requests` constraint for Python < 3.8\n",
            "\n",
            "2025-05-23 19:29:43.399371: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-05-23 19:29:43.401903: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2025-05-23 19:29:43.453613: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-05-23 19:29:44.714199: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "ClearML results page: https://app.clear.ml/projects/63364fc9874b49b8a9c6b822d35c26c6/experiments/6c12c89305ba4a558fc25ffbe37c1287/output/log\n",
            "==================================================\n",
            "STEP 1: Dataset Artifact Creation\n",
            "==================================================\n",
            "Creating sample Amazon e-commerce dataset...\n",
            "Generated dataset with 10000 samples\n",
            "Dataset shape: (10000, 9)\n",
            "\n",
            "Dataset info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 9 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   user_id           10000 non-null  int64  \n",
            " 1   product_name      10000 non-null  object \n",
            " 2   discounted_price  10000 non-null  float64\n",
            " 3   actual_price      10000 non-null  float64\n",
            " 4   rating            10000 non-null  float64\n",
            " 5   rating_count      10000 non-null  int64  \n",
            " 6   Sales             10000 non-null  float64\n",
            " 7   Quantity          10000 non-null  int64  \n",
            " 8   Profit            10000 non-null  float64\n",
            "dtypes: float64(5), int64(3), object(1)\n",
            "memory usage: 703.3+ KB\n",
            "None\n",
            "\n",
            "First 5 rows:\n",
            "   user_id product_name  discounted_price  ...        Sales  Quantity      Profit\n",
            "0      103  product_442        261.169553  ...  3477.204533        20   43.952516\n",
            "1      436  product_279        171.994397  ...  8815.900863        94  181.927194\n",
            "2      861  product_251        431.650628  ...  9940.407787        37  110.210083\n",
            "3      271  product_310        242.142475  ...  1695.702447        20   81.516778\n",
            "4      107  product_208        401.793536  ...   333.431611        60  186.183288\n",
            "\n",
            "[5 rows x 9 columns]\n",
            "\n",
            "Performing data validation...\n",
            "Missing values per column:\n",
            "user_id             0\n",
            "product_name        0\n",
            "discounted_price    0\n",
            "actual_price        0\n",
            "rating              0\n",
            "rating_count        0\n",
            "Sales               0\n",
            "Quantity            0\n",
            "Profit              0\n",
            "dtype: int64\n",
            "Negative values check:\n",
            "  discounted_price: 0 negative values\n",
            "  actual_price: 0 negative values\n",
            "  rating: 0 negative values\n",
            "  Sales: 0 negative values\n",
            "  Quantity: 0 negative values\n",
            "  Profit: 0 negative values\n",
            "Ratings out of 1-5 range: 0\n",
            "Discounted price > actual price: 0\n",
            "\n",
            "Splitting data with ratio 0.8\n",
            "Training set size: 8000\n",
            "Test set size: 2000\n",
            "\n",
            "Saved datasets to:\n",
            "  - train_data.csv\n",
            "  - test_data.csv\n",
            "  - full_dataset.csv\n",
            "\n",
            "Creating ClearML dataset: amazon_ecommerce_data\n",
            "ClearML results page: https://app.clear.ml/projects/c4d998f383694ce9911229d45afc2892/experiments/e0ec7d869ec745869ebe4fe5905528ba/output/log\n",
            "ClearML dataset page: https://app.clear.ml/datasets/simple/c4d998f383694ce9911229d45afc2892/experiments/e0ec7d869ec745869ebe4fe5905528ba\n",
            "Dataset created with 10000 total samples\n",
            "Training samples: 8000\n",
            "Test samples: 2000\n",
            "Features: ['user_id', 'product_name', 'discounted_price', 'actual_price', 'rating', 'rating_count', 'Sales', 'Quantity', 'Profit']\n",
            "Uploading dataset changes (3 files compressed to 1.59 MiB) to https://files.clear.ml\n",
            "File compression and upload completed: total size 1.59 MiB, 1 chunk(s) stored (average size 1.59 MiB)\n",
            "Dataset created successfully with ID: e0ec7d869ec745869ebe4fe5905528ba\n",
            "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "\n",
            "==================================================\n",
            "STEP 1 COMPLETED SUCCESSFULLY\n",
            "==================================================\n",
            "Dataset artifact created: e0ec7d869ec745869ebe4fe5905528ba\n",
            "Training samples: 8000\n",
            "Test samples: 2000\n",
            "Total features: 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/e-shopping-recommendation/step2_data_preprocessing.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cih2Vt-Np-H4",
        "outputId": "eeb168e0-ca79-4b00-c423-1fed0c4147ef"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ClearML Task: created new task id=cb8d133f414646ec8d1f755850230409\n",
            "CLEARML new package available: UPGRADE to v2.0.0 is recommended!\n",
            "Release Notes:\n",
            "### New Features\n",
            "\n",
            "- Clean up exception handeling in cleanup_service.py (#1387, thanks @PixelWelt!)\n",
            "- Add support for `clearml-task` command line options `--force-no-requirements`, `--skip-repo-detection` and `--skip-python-env-install`\n",
            "- Allow calling the same pipeline step multiple times with inputs that originate from tasks/controller\n",
            "- Add `Task.upload_artifact()` argument `sort_keys` to allow disabling sorting yaml/json keys when uploading artifacts\n",
            "- Add python annotations to all methods\n",
            "- Update `pyjwt` constraint version\n",
            "\n",
            "\n",
            "### Bug Fixes\n",
            "\n",
            "- Fix local file uploads without scheme (#1326, thanks @d-vignesh!)\n",
            "- Fix argument order mismatch in `PipelineController` (#1407, thanks @rashboldb!)\n",
            "- Fix `_logger` property might be `None` in Session (#1412, thanks @AH-Merii!)\n",
            "- Fix unhandled `None` value in project IDs when listing all datasets (#1413, thanks @AH-Merii!)\n",
            "- Fix typo in config exception string (#1418, thanks @AH-Merii!)\n",
            "- Fix experiments are created twice during HPO (#644)\n",
            "- Fix `clearml-task`-run HPO breaks up (#1151)\n",
            "- Fix oversized event reports cause subsequent events to be lost (#1316)\n",
            "- Fix downloading datasets with multiple parents might not work (#1398)\n",
            "- Fix GPU reporting fails to detect GPU when the `NVIDIA_VISIBLE_DEVICES` env var contains a directory reference\n",
            "- Fix `verify` configuration option for S3 storage (boto3) is not used when testing buckets\n",
            "- Fix `PipelineDecorator.component()` ignores `*args` and crashes with `**kwargs`\n",
            "- Fix Pipelines ran via `clearml-task` do not appear in the UI\n",
            "- Fix task log URL print for API v2.31 should show `\"/tasks/{}/output/log\"`\n",
            "- Fix `tqdm` upload/download reporting, remove warning\n",
            "- Fix pipeline from CLI with no args fails\n",
            "- Fix `pillow` constraint for Python<=3.7\n",
            "- Fix `requests` constraint for Python < 3.8\n",
            "\n",
            "2025-05-23 19:31:40.535456: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-05-23 19:31:40.538064: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2025-05-23 19:31:40.591398: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-05-23 19:31:41.545685: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "ClearML results page: https://app.clear.ml/projects/63364fc9874b49b8a9c6b822d35c26c6/experiments/cb8d133f414646ec8d1f755850230409/output/log\n",
            "==================================================\n",
            "STEP 2: Data Preprocessing\n",
            "==================================================\n",
            "Loading dataset from task: 6c12c89305ba4a558fc25ffbe37c1287\n",
            "2025-05-23 19:31:48,845 - clearml - INFO - Dataset.get() did not specify alias. Dataset information will not be automatically logged in ClearML Server.\n",
            "2025-05-23 19:32:01,273 - clearml - INFO - Dataset.get() did not specify alias. Dataset information will not be automatically logged in ClearML Server.\n",
            "Loaded dataset with 10000 samples\n",
            "Original dataset shape: (10000, 9)\n",
            "\n",
            "Original dataset info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 9 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   user_id           10000 non-null  int64  \n",
            " 1   product_name      10000 non-null  object \n",
            " 2   discounted_price  10000 non-null  float64\n",
            " 3   actual_price      10000 non-null  float64\n",
            " 4   rating            10000 non-null  float64\n",
            " 5   rating_count      10000 non-null  int64  \n",
            " 6   Sales             10000 non-null  float64\n",
            " 7   Quantity          10000 non-null  int64  \n",
            " 8   Profit            10000 non-null  float64\n",
            "dtypes: float64(5), int64(3), object(1)\n",
            "memory usage: 703.3+ KB\n",
            "None\n",
            "\n",
            "First 5 rows:\n",
            "   user_id product_name  discounted_price  ...        Sales  Quantity      Profit\n",
            "0      103  product_442        261.169553  ...  3477.204533        20   43.952516\n",
            "1      436  product_279        171.994397  ...  8815.900863        94  181.927194\n",
            "2      861  product_251        431.650628  ...  9940.407787        37  110.210083\n",
            "3      271  product_310        242.142475  ...  1695.702447        20   81.516778\n",
            "4      107  product_208        401.793536  ...   333.431611        60  186.183288\n",
            "\n",
            "[5 rows x 9 columns]\n",
            "\n",
            "==============================\n",
            "DATA CLEANING & PREPROCESSING\n",
            "==============================\n",
            "\n",
            "1. Handling missing values...\n",
            "Missing values before processing:\n",
            "Series([], dtype: int64)\n",
            "Missing values after processing:\n",
            "Series([], dtype: int64)\n",
            "\n",
            "2. Data type conversion and cleaning...\n",
            "  Standardized product names: 500 unique products\n",
            "\n",
            "3. Handling negative or unreasonable values...\n",
            "\n",
            "4. Feature engineering...\n",
            "  Created discount_amount and discount_percentage features\n",
            "  Created price_per_unit feature\n",
            "  Created profit_margin feature\n",
            "  Created rating_category feature\n",
            "\n",
            "5. Outlier detection and removal (threshold: 3.0 std)...\n",
            "  Found 23 outliers in 'discount_amount'\n",
            "  Found 184 outliers in 'price_per_unit'\n",
            "  Found 175 outliers in 'profit_margin'\n",
            "  Removed 382 samples due to outliers\n",
            "  Dataset size after outlier removal: 9618\n",
            "\n",
            "6. Preparing features for modeling...\n",
            "\n",
            "7. Feature scaling...\n",
            "  Applied StandardScaler to clustering features\n",
            "  Saved scaler to standard_scaler.pkl\n",
            "\n",
            "8. Creating train-test split (test_size: 0.25)...\n",
            "  Training set size: 7213\n",
            "  Test set size: 2405\n",
            "\n",
            "9. Data validation and quality checks...\n",
            "  Data distribution summary:\n",
            "       discounted_price  actual_price       rating  rating_count       Profit\n",
            "count       9618.000000   9618.000000  9618.000000   9618.000000  9618.000000\n",
            "mean         257.935428    374.983302     2.998606    497.099189   104.577582\n",
            "std          141.394072    130.465970     1.157870    289.815381    55.406423\n",
            "min           10.077295     26.627224     1.000022      1.000000    10.021871\n",
            "25%          135.681839    283.715330     1.989548    243.000000    56.841080\n",
            "50%          258.592198    392.436523     3.004791    497.000000   103.563140\n",
            "75%          380.802871    475.619108     3.994263    748.000000   153.659978\n",
            "max          499.963165    599.942072     4.999157    999.000000   199.938563\n",
            "  Final data quality check:\n",
            "    Total samples: 9618\n",
            "    Total features: 14\n",
            "    Missing values: 0\n",
            "    Duplicate rows: 0\n",
            "\n",
            "10. Saving processed data...\n",
            "  Saved processed datasets:\n",
            "    - processed_train_data.csv\n",
            "    - processed_test_data.csv\n",
            "    - processed_full_data.csv\n",
            "    - clustering_features.csv\n",
            "\n",
            "11. Creating ClearML artifacts...\n",
            "\n",
            "12. Generating visualization reports...\n",
            "\n",
            "==================================================\n",
            "STEP 2 COMPLETED SUCCESSFULLY\n",
            "==================================================\n",
            "Processed dataset samples: 9618\n",
            "Training samples: 7213\n",
            "Test samples: 2405\n",
            "Total features: 14\n",
            "Clustering features: 5\n",
            "Outliers removed: 382\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/e-shopping-recommendation/step3_train_model.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajK0jyziqk-Z",
        "outputId": "a91d0604-12b0-44b2-e83d-0c3391696d95"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ClearML Task: created new task id=719e41ed1ff942b79778bfac03e7e121\n",
            "CLEARML new package available: UPGRADE to v2.0.0 is recommended!\n",
            "Release Notes:\n",
            "### New Features\n",
            "\n",
            "- Clean up exception handeling in cleanup_service.py (#1387, thanks @PixelWelt!)\n",
            "- Add support for `clearml-task` command line options `--force-no-requirements`, `--skip-repo-detection` and `--skip-python-env-install`\n",
            "- Allow calling the same pipeline step multiple times with inputs that originate from tasks/controller\n",
            "- Add `Task.upload_artifact()` argument `sort_keys` to allow disabling sorting yaml/json keys when uploading artifacts\n",
            "- Add python annotations to all methods\n",
            "- Update `pyjwt` constraint version\n",
            "\n",
            "\n",
            "### Bug Fixes\n",
            "\n",
            "- Fix local file uploads without scheme (#1326, thanks @d-vignesh!)\n",
            "- Fix argument order mismatch in `PipelineController` (#1407, thanks @rashboldb!)\n",
            "- Fix `_logger` property might be `None` in Session (#1412, thanks @AH-Merii!)\n",
            "- Fix unhandled `None` value in project IDs when listing all datasets (#1413, thanks @AH-Merii!)\n",
            "- Fix typo in config exception string (#1418, thanks @AH-Merii!)\n",
            "- Fix experiments are created twice during HPO (#644)\n",
            "- Fix `clearml-task`-run HPO breaks up (#1151)\n",
            "- Fix oversized event reports cause subsequent events to be lost (#1316)\n",
            "- Fix downloading datasets with multiple parents might not work (#1398)\n",
            "- Fix GPU reporting fails to detect GPU when the `NVIDIA_VISIBLE_DEVICES` env var contains a directory reference\n",
            "- Fix `verify` configuration option for S3 storage (boto3) is not used when testing buckets\n",
            "- Fix `PipelineDecorator.component()` ignores `*args` and crashes with `**kwargs`\n",
            "- Fix Pipelines ran via `clearml-task` do not appear in the UI\n",
            "- Fix task log URL print for API v2.31 should show `\"/tasks/{}/output/log\"`\n",
            "- Fix `tqdm` upload/download reporting, remove warning\n",
            "- Fix pipeline from CLI with no args fails\n",
            "- Fix `pillow` constraint for Python<=3.7\n",
            "- Fix `requests` constraint for Python < 3.8\n",
            "\n",
            "2025-05-23 19:33:13.972763: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-05-23 19:33:13.975391: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2025-05-23 19:33:14.029844: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-05-23 19:33:15.187952: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "ClearML results page: https://app.clear.ml/projects/63364fc9874b49b8a9c6b822d35c26c6/experiments/719e41ed1ff942b79778bfac03e7e121/output/log\n",
            "==================================================\n",
            "STEP 3: Model Training\n",
            "==================================================\n",
            "Loading processed data from task: cb8d133f414646ec8d1f755850230409\n",
            "Loaded processed dataset with 9618 samples\n",
            "Clustering features shape: (9618, 5)\n",
            "Dataset shape: (9618, 14)\n",
            "Features for clustering: ['discounted_price', 'actual_price', 'rating', 'rating_count', 'Profit']\n",
            "\n",
            "========================================\n",
            "PART 1: CLUSTERING MODEL TRAINING\n",
            "========================================\n",
            "\n",
            "1. Preparing clustering data...\n",
            "Applied StandardScaler to clustering features\n",
            "Scaled features shape: (9618, 5)\n",
            "\n",
            "2. Finding optimal number of clusters (range: [2, 10])...\n",
            "  Testing k=2...\n",
            "    Inertia: 38386.75, Silhouette: 0.190, Calinski-Harabasz: 2430.72, Davies-Bouldin: 1.925\n",
            "  Testing k=3...\n",
            "    Inertia: 33593.26, Silhouette: 0.167, Calinski-Harabasz: 2074.63, Davies-Bouldin: 1.854\n",
            "  Testing k=4...\n",
            "    Inertia: 30443.45, Silhouette: 0.159, Calinski-Harabasz: 1857.60, Davies-Bouldin: 1.674\n",
            "  Testing k=5...\n",
            "    Inertia: 27738.06, Silhouette: 0.163, Calinski-Harabasz: 1763.33, Davies-Bouldin: 1.602\n",
            "  Testing k=6...\n",
            "    Inertia: 25577.55, Silhouette: 0.169, Calinski-Harabasz: 1692.04, Davies-Bouldin: 1.573\n",
            "  Testing k=7...\n",
            "    Inertia: 23777.50, Silhouette: 0.170, Calinski-Harabasz: 1637.88, Davies-Bouldin: 1.531\n",
            "  Testing k=8...\n",
            "    Inertia: 22301.30, Silhouette: 0.174, Calinski-Harabasz: 1587.55, Davies-Bouldin: 1.418\n",
            "  Testing k=9...\n",
            "    Inertia: 20801.72, Silhouette: 0.185, Calinski-Harabasz: 1575.68, Davies-Bouldin: 1.300\n",
            "  Testing k=10...\n",
            "    Inertia: 19809.64, Silhouette: 0.178, Calinski-Harabasz: 1524.06, Davies-Bouldin: 1.331\n",
            "\n",
            "  Optimal number of clusters: 2\n",
            "  Best silhouette score: 0.190\n",
            "\n",
            "3. Training final clustering model with k=2...\n",
            "Final clustering metrics:\n",
            "  Inertia: 38386.75\n",
            "  Silhouette Score: 0.190\n",
            "  Calinski-Harabasz Score: 2430.72\n",
            "  Davies-Bouldin Score: 1.925\n",
            "\n",
            "4. Analyzing clusters...\n",
            "Cluster summary statistics:\n",
            "        discounted_price                    ...      Profit                 \n",
            "                    mean         std count  ...        mean        std count\n",
            "Cluster                                     ...                             \n",
            "0             143.946843   84.832532  4253  ...  105.011357  55.185731  4253\n",
            "1             348.297675  108.027946  5365  ...  104.233715  55.583483  5365\n",
            "\n",
            "[2 rows x 15 columns]\n",
            "\n",
            "Cluster sizes:\n",
            "  Cluster 0: 4253 samples (44.2%)\n",
            "  Cluster 1: 5365 samples (55.8%)\n",
            "\n",
            "5. Generating clustering visualizations...\n",
            "\n",
            "========================================\n",
            "PART 2: RECOMMENDATION MODEL TRAINING\n",
            "========================================\n",
            "\n",
            "1. Preparing recommendation data...\n",
            "Recommendation data shape: (9618, 15)\n",
            "Valid users: 1000\n",
            "Valid products: 500\n",
            "\n",
            "2. Creating user-product interaction matrix...\n",
            "User-product matrix shape: (1000, 500)\n",
            "Matrix sparsity: 98.09%\n",
            "\n",
            "3. Calculating similarity matrices using cosine similarity...\n",
            "Product similarity matrix shape: (500, 500)\n",
            "User similarity matrix shape: (1000, 1000)\n",
            "\n",
            "4. Creating recommendation system...\n",
            "\n",
            "5. Testing recommendation system...\n",
            "Sample product-based recommendations:\n",
            "  Similar to 'product_1': ['product_391', 'product_96', 'product_309']\n",
            "  Similar to 'product_10': ['product_207', 'product_201', 'product_452']\n",
            "  Similar to 'product_100': ['product_131', 'product_363', 'product_91']\n",
            "  Similar to 'product_101': ['product_343', 'product_98', 'product_177']\n",
            "  Similar to 'product_102': ['product_364', 'product_237', 'product_354']\n",
            "\n",
            "Sample user-based recommendations:\n",
            "  For user 1: ['product_374', 'product_80', 'product_83']\n",
            "  For user 2: ['product_387', 'product_74', 'product_323']\n",
            "  For user 3: ['product_411', 'product_476', 'product_454']\n",
            "\n",
            "6. Evaluating recommendation system...\n",
            "Recommendation system metrics:\n",
            "  total_interactions: 9618\n",
            "  unique_users: 1000\n",
            "  unique_products: 500\n",
            "  avg_interactions_per_user: 9.618\n",
            "  avg_interactions_per_product: 19.236\n",
            "  matrix_sparsity: 0.980926\n",
            "  similarity_metric: cosine\n",
            "\n",
            "7. Generating recommendation visualizations...\n",
            "\n",
            "==============================\n",
            "SAVING MODELS AND ARTIFACTS\n",
            "==============================\n",
            "Saved clustering model to trained_clustering_model.pkl\n",
            "Saved clustered data to data_with_clusters.csv\n",
            "Saved user-product matrix to user_product_matrix.pkl\n",
            "Saved product similarity matrix to product_similarity_matrix.pkl\n",
            "Saved user similarity matrix to user_similarity_matrix.pkl\n",
            "\n",
            "Uploading artifacts to ClearML...\n",
            "\n",
            "==================================================\n",
            "STEP 3 COMPLETED SUCCESSFULLY\n",
            "==================================================\n",
            "Clustering Model:\n",
            "  Algorithm: kmeans\n",
            "  Number of clusters: 2\n",
            "  Silhouette score: 0.190\n",
            "  Samples clustered: 9618\n",
            "Recommendation Model:\n",
            "  Users: 1000\n",
            "  Products: 500\n",
            "  Interactions: 9618\n",
            "  Matrix sparsity: 98.09%\n",
            "2025-05-23 19:34:13,504 - clearml - WARNING - Skipping upload, could not find object file '/content/e-shopping-recommendation/user_product_matrix.pkl'\n",
            "2025-05-23 19:34:13,505 - clearml - WARNING - Skipping upload, could not find object file '/content/e-shopping-recommendation/product_similarity_matrix.pkl'\n",
            "2025-05-23 19:34:13,506 - clearml - WARNING - Skipping upload, could not find object file '/content/e-shopping-recommendation/user_similarity_matrix.pkl'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install array-api-compat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaHZgWax3KBi",
        "outputId": "63527e68-a1dc-45aa-dafd-b7c1bf58dcd2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting array-api-compat\n",
            "  Downloading array_api_compat-1.12.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Downloading array_api_compat-1.12.0-py3-none-any.whl (58 kB)\n",
            "\u001b[?25l   \u001b[90m\u001b[0m \u001b[32m0.0/58.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m\u001b[0m \u001b[32m58.2/58.2 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: array-api-compat\n",
            "Successfully installed array-api-compat-1.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/e-shopping-recommendation/task_hpo.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BsR1DWg7cZW",
        "outputId": "4475f0e0-4975-43b1-8a23-bcfed3bc74dd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ClearML Task: created new task id=7b98e12fcab84fedbcadb378ac30d3c8\n",
            "CLEARML new package available: UPGRADE to v2.0.0 is recommended!\n",
            "Release Notes:\n",
            "### New Features\n",
            "\n",
            "- Clean up exception handeling in cleanup_service.py (#1387, thanks @PixelWelt!)\n",
            "- Add support for `clearml-task` command line options `--force-no-requirements`, `--skip-repo-detection` and `--skip-python-env-install`\n",
            "- Allow calling the same pipeline step multiple times with inputs that originate from tasks/controller\n",
            "- Add `Task.upload_artifact()` argument `sort_keys` to allow disabling sorting yaml/json keys when uploading artifacts\n",
            "- Add python annotations to all methods\n",
            "- Update `pyjwt` constraint version\n",
            "\n",
            "\n",
            "### Bug Fixes\n",
            "\n",
            "- Fix local file uploads without scheme (#1326, thanks @d-vignesh!)\n",
            "- Fix argument order mismatch in `PipelineController` (#1407, thanks @rashboldb!)\n",
            "- Fix `_logger` property might be `None` in Session (#1412, thanks @AH-Merii!)\n",
            "- Fix unhandled `None` value in project IDs when listing all datasets (#1413, thanks @AH-Merii!)\n",
            "- Fix typo in config exception string (#1418, thanks @AH-Merii!)\n",
            "- Fix experiments are created twice during HPO (#644)\n",
            "- Fix `clearml-task`-run HPO breaks up (#1151)\n",
            "- Fix oversized event reports cause subsequent events to be lost (#1316)\n",
            "- Fix downloading datasets with multiple parents might not work (#1398)\n",
            "- Fix GPU reporting fails to detect GPU when the `NVIDIA_VISIBLE_DEVICES` env var contains a directory reference\n",
            "- Fix `verify` configuration option for S3 storage (boto3) is not used when testing buckets\n",
            "- Fix `PipelineDecorator.component()` ignores `*args` and crashes with `**kwargs`\n",
            "- Fix Pipelines ran via `clearml-task` do not appear in the UI\n",
            "- Fix task log URL print for API v2.31 should show `\"/tasks/{}/output/log\"`\n",
            "- Fix `tqdm` upload/download reporting, remove warning\n",
            "- Fix pipeline from CLI with no args fails\n",
            "- Fix `pillow` constraint for Python<=3.7\n",
            "- Fix `requests` constraint for Python < 3.8\n",
            "\n",
            "2025-05-23 19:37:07.274115: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-05-23 19:37:07.276660: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2025-05-23 19:37:07.333134: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-05-23 19:37:08.605246: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "ClearML results page: https://app.clear.ml/projects/63364fc9874b49b8a9c6b822d35c26c6/experiments/7b98e12fcab84fedbcadb378ac30d3c8/output/log\n",
            "INFO:__main__:Connected parameters: {'base_train_task_id': '719e41ed1ff942b79778bfac03e7e121', 'num_trials': 3, 'time_limit_minutes': 20, 'run_as_service': False, 'test_queue': 'pipeline', 'processed_dataset_id': '', 'n_clusters_max': 10, 'max_iter': 300, 'outlier_threshold': 3.0, 'min_interactions': 2}\n",
            "INFO:__main__:No dataset_id in General namespace, using from args: \n",
            "INFO:__main__:Using fixed dataset ID: your_dataset_id_here\n",
            "INFO:__main__:Using dataset ID: your_dataset_id_here\n",
            "INFO:__main__:Using base training task ID: 719e41ed1ff942b79778bfac03e7e121\n",
            "INFO:__main__:Dataset verification skipped for e-commerce project\n",
            "2025-05-23 19:37:18,065 - clearml.automation.optimization - WARNING - Could not find requested hyper-parameters ['n_clusters_range_max', 'max_iter', 'outlier_threshold', 'min_interactions', 'clustering_algorithm', 'similarity_metric'] on base task 719e41ed1ff942b79778bfac03e7e121\n",
            "2025-05-23 19:37:18,740 - clearml.automation.optimization - WARNING - Could not find requested metric ('Clustering', 'Silhouette Score') report on base task 719e41ed1ff942b79778bfac03e7e121\n",
            "INFO:__main__:Starting HPO task...\n",
            "INFO:__main__:Waiting for optimization to complete (time limit: 20 minutes)...\n",
            "Progress report #0 completed, sleeping for 0.25 minutes\n",
            "2025-05-23 19:37:25,635 - clearml.automation.optimization - INFO - Creating new Task: {'n_clusters_range_max': 8, 'max_iter': 392, 'outlier_threshold': 3.171574707804543, 'min_interactions': 2, 'clustering_algorithm': 'minibatch_kmeans', 'similarity_metric': 'euclidean'}\n",
            "2025-05-23 19:37:34,179 - clearml.automation.optimization - INFO - Creating new Task: {'n_clusters_range_max': 8, 'max_iter': 257, 'outlier_threshold': 2.7831026910580254, 'min_interactions': 2, 'clustering_algorithm': 'minibatch_kmeans', 'similarity_metric': 'cosine'}\n",
            "Progress report #1 completed, sleeping for 5.0 minutes\n",
            "2025-05-23 19:39:48,278 - clearml.automation.optimization - INFO - Creating new Task: {'n_clusters_range_max': 9, 'max_iter': 425, 'outlier_threshold': 2.797478108109929, 'min_interactions': 1, 'clustering_algorithm': 'minibatch_kmeans', 'similarity_metric': 'euclidean'}\n",
            "INFO:__main__:Best experiment: 6bf464b30b4d43e8bf706e0f47b6fdf2\n",
            "INFO:__main__:Best experiment parameters:\n",
            "INFO:__main__:  - clustering_algorithm: None\n",
            "INFO:__main__:  - n_clusters_range_max: None\n",
            "INFO:__main__:  - max_iter: None\n",
            "INFO:__main__:  - outlier_threshold: None\n",
            "INFO:__main__:  - similarity_metric: None\n",
            "INFO:__main__:  - min_interactions: None\n",
            "INFO:__main__:Best silhouette score: None\n",
            "INFO:__main__:Best calinski score: None\n",
            "INFO:__main__:Recommendation users: None\n",
            "INFO:__main__:Experiment 1: ID=6bf464b30b4d43e8bf706e0f47b6fdf2, Silhouette=None\n",
            "INFO:__main__:Experiment 2: ID=91c62a0ddf7446a098d8c0e5ff8ee05a, Silhouette=None\n",
            "INFO:__main__:Experiment 3: ID=c03e4ad41c154a08851cd631a465eccc, Silhouette=None\n",
            "INFO:__main__:Saved best parameters with silhouette score: None\n",
            "INFO:__main__:Best parameters saved as both artifact and task parameters\n",
            "INFO:__main__:Optimizer stopped\n",
            "INFO:__main__:============================================================\n",
            "INFO:__main__:E-COMMERCE RECOMMENDATION SYSTEM HPO COMPLETED\n",
            "INFO:__main__:============================================================\n",
            "INFO:__main__:Check ClearML UI for:\n",
            "INFO:__main__:  - Best experiment parameters\n",
            "INFO:__main__:  - Clustering performance metrics\n",
            "INFO:__main__:  - Recommendation system results\n",
            "INFO:__main__:Use best parameters in final_model.py for deployment\n",
            "E-commerce HPO completed - ready for final model!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/e-shopping-recommendation/final_model.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPSZ610SzqGI",
        "outputId": "3cd5d310-aa3c-4a0c-a483-4a7996fd37a0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ClearML Task: created new task id=497d1290593e4ed28eccec75d44b9b25\n",
            "CLEARML new package available: UPGRADE to v2.0.0 is recommended!\n",
            "Release Notes:\n",
            "### New Features\n",
            "\n",
            "- Clean up exception handeling in cleanup_service.py (#1387, thanks @PixelWelt!)\n",
            "- Add support for `clearml-task` command line options `--force-no-requirements`, `--skip-repo-detection` and `--skip-python-env-install`\n",
            "- Allow calling the same pipeline step multiple times with inputs that originate from tasks/controller\n",
            "- Add `Task.upload_artifact()` argument `sort_keys` to allow disabling sorting yaml/json keys when uploading artifacts\n",
            "- Add python annotations to all methods\n",
            "- Update `pyjwt` constraint version\n",
            "\n",
            "\n",
            "### Bug Fixes\n",
            "\n",
            "- Fix local file uploads without scheme (#1326, thanks @d-vignesh!)\n",
            "- Fix argument order mismatch in `PipelineController` (#1407, thanks @rashboldb!)\n",
            "- Fix `_logger` property might be `None` in Session (#1412, thanks @AH-Merii!)\n",
            "- Fix unhandled `None` value in project IDs when listing all datasets (#1413, thanks @AH-Merii!)\n",
            "- Fix typo in config exception string (#1418, thanks @AH-Merii!)\n",
            "- Fix experiments are created twice during HPO (#644)\n",
            "- Fix `clearml-task`-run HPO breaks up (#1151)\n",
            "- Fix oversized event reports cause subsequent events to be lost (#1316)\n",
            "- Fix downloading datasets with multiple parents might not work (#1398)\n",
            "- Fix GPU reporting fails to detect GPU when the `NVIDIA_VISIBLE_DEVICES` env var contains a directory reference\n",
            "- Fix `verify` configuration option for S3 storage (boto3) is not used when testing buckets\n",
            "- Fix `PipelineDecorator.component()` ignores `*args` and crashes with `**kwargs`\n",
            "- Fix Pipelines ran via `clearml-task` do not appear in the UI\n",
            "- Fix task log URL print for API v2.31 should show `\"/tasks/{}/output/log\"`\n",
            "- Fix `tqdm` upload/download reporting, remove warning\n",
            "- Fix pipeline from CLI with no args fails\n",
            "- Fix `pillow` constraint for Python<=3.7\n",
            "- Fix `requests` constraint for Python < 3.8\n",
            "\n",
            "2025-05-23 20:00:41.819979: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-05-23 20:00:41.822517: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2025-05-23 20:00:41.877880: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-05-23 20:00:43.224405: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "ClearML results page: https://app.clear.ml/projects/63364fc9874b49b8a9c6b822d35c26c6/experiments/497d1290593e4ed28eccec75d44b9b25/output/log\n",
            "INFO:__main__:Connected parameters: {'processed_dataset_id': 'cb8d133f414646ec8d1f755850230409', 'hpo_task_id': '7b98e12fcab84fedbcadb378ac30d3c8', 'test_queue': 'pipeline', 'n_clusters_range_max': 5, 'max_iter': 300, 'outlier_threshold': 3.0, 'min_interactions': 2, 'clustering_algorithm': 'kmeans', 'similarity_metric': 'cosine'}\n",
            "INFO:__main__:Received dataset ID from parameters: cb8d133f414646ec8d1f755850230409\n",
            "INFO:__main__:Retrieved HPO task: HPO: E-commerce Recommendation System\n",
            "INFO:__main__:Best parameters not found in task parameters, trying artifact...\n",
            "INFO:__main__:Downloaded best parameters from: /root/.clearml/cache/storage_manager/global/d3b8f54e2fee89fa4ba14a509eab7ebd.best_parameters_ecommerce.json\n",
            "INFO:__main__:Using best parameters from HPO: {'General/dataset_task_id': 'cb8d133f414646ec8d1f755850230409', 'General/clustering_algorithm': 'minibatch_kmeans', 'General/n_clusters_range': '[2, 10]', 'General/random_state': '42', 'General/max_iter': '425', 'General/n_init': '10', 'General/optimize_clusters': 'True', 'General/train_recommendation': 'True', 'General/similarity_metric': 'euclidean', 'General/min_interactions': '1', 'General/n_clusters_range_max': '9', 'General/outlier_threshold': '2.797478108109929'}\n",
            "INFO:__main__:Best silhouette score from HPO: None\n",
            "INFO:__main__:Dataset verification skipped for e-commerce project\n",
            "INFO:__main__:Data loaded successfully from preprocessing task. Samples: 9618\n",
            "INFO:__main__:Clustering features prepared. Shape: (9618, 5)\n",
            "INFO:__main__:Initializing clustering model...\n",
            "INFO:__main__:Model initialized: kmeans with 5 clusters\n",
            "INFO:__main__:Starting model training...\n",
            "Training Progress:   0% 0/100 [00:00<?, ?it/s]INFO:__main__:Training Progress: 1.0%\n",
            "INFO:__main__:Training Progress: 11.0%\n",
            "INFO:__main__:Training Progress: 21.0%\n",
            "INFO:__main__:Training Progress: 31.0%\n",
            "INFO:__main__:Training Progress: 41.0%\n",
            "INFO:__main__:Training Progress: 51.0%\n",
            "INFO:__main__:Training Progress: 61.0%\n",
            "INFO:__main__:Training Progress: 71.0%\n",
            "INFO:__main__:Training Progress: 81.0%\n",
            "INFO:__main__:Training Progress: 91.0%\n",
            "Training Progress: 100% 100/100 [00:00<00:00, 18071.11it/s]\n",
            "INFO:__main__:Performing final model fitting...\n",
            "INFO:__main__:Training completed in 1.40 seconds\n",
            "INFO:__main__:Calculating performance metrics...\n",
            "INFO:__main__:Final Performance Metrics:\n",
            "INFO:__main__:  Silhouette Score: 0.1634\n",
            "INFO:__main__:  Calinski-Harabasz Score: 1763.33\n",
            "INFO:__main__:  Davies-Bouldin Score: 1.6021\n",
            "INFO:__main__:  Inertia: 27738.06\n",
            "INFO:__main__:Building recommendation system...\n",
            "INFO:__main__:Recommendation System Metrics:\n",
            "INFO:__main__:  Total Interactions: 9617\n",
            "INFO:__main__:  Unique Users: 999\n",
            "INFO:__main__:  Unique Products: 500\n",
            "INFO:__main__:Saving final model...\n",
            "INFO:__main__:Model saved and uploaded as artifact\n",
            "INFO:__main__:Final model summary: {'model_type': 'E-commerce Clustering + Recommendation System', 'clustering_algorithm': 'kmeans', 'n_clusters': 5, 'performance_metrics': {'silhouette_score': 0.16341741279168165, 'calinski_harabasz_score': 1763.3256728756694, 'davies_bouldin_score': 1.6020960919164664, 'inertia': 27738.05907636755}, 'training_time_seconds': 1.3994543552398682, 'samples_processed': 9618, 'best_hpo_score': None, 'recommendation_system_built': True, 'parameters_used': {'n_clusters_range_max': 5, 'max_iter': 300, 'outlier_threshold': 3.0, 'min_interactions': 2, 'clustering_algorithm': 'kmeans', 'similarity_metric': 'cosine'}}\n",
            "E-commerce recommendation system training completed successfully!\n",
            "Final Silhouette Score: 0.1634\n",
            "Model ready for deployment!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmrTXLS5r8AR",
        "outputId": "2eea5c68-591a-46d8-fc09-18ced8b5ca78"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Amazon.zip                         'POC code'\n",
            " \u001b[0m\u001b[01;34massets\u001b[0m/                             README.md\n",
            " cleaned_amazon_data_final.csv.zip   requirements.txt\n",
            "'cleaned data.zip'                   step1_dataset_artifact.py\n",
            " \u001b[01;34mfigs\u001b[0m/                               step2_data_preprocessing.py\n",
            " final_model.py                      step3_train_model.py\n",
            " main.py                             task_hpo.py\n",
            " pipeline_from_tasks.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "649Kq-MwGPKs",
        "outputId": "ba0e16c9-be2a-4c10-dacd-aa3bf20f804b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: numpy\n",
            "Version: 1.24.3\n",
            "Summary: Fundamental package for array computing in Python\n",
            "Home-page: https://www.numpy.org\n",
            "Author: Travis E. Oliphant et al.\n",
            "Author-email: \n",
            "License: BSD-3-Clause\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: \n",
            "Required-by: accelerate, albucore, albumentations, ale-py, arviz, astropy, autograd, bigframes, blis, blosc2, bokeh, Bottleneck, bqplot, chex, clarabel, clearml, cmdstanpy, contourpy, cudf-cu12, cufflinks, cuml-cu12, cupy-cuda12x, cuvs-cu12, cvxpy, cyipopt, dask-cuda, dask-cudf-cu12, datascience, datasets, db-dtypes, diffusers, dm-tree, dopamine_rl, flax, folium, geemap, geopandas, gym, gymnasium, h5py, hdbscan, highspy, holoviews, hyperopt, imageio, imbalanced-learn, jax, jaxlib, keras-hub, libpysal, librosa, lightgbm, matplotlib, matplotlib-venn, missingno, mizani, ml-dtypes, mlxtend, moviepy, music21, nibabel, numba, numexpr, nx-cugraph-cu12, opencv-contrib-python, opencv-python, opencv-python-headless, optax, optuna, orbax-checkpoint, osqp, pandas, pandas-gbq, pandas-stubs, patsy, peft, plotnine, prophet, pycocotools, pyerfa, pylibcugraph-cu12, pylibraft-cu12, pymc, pyogrio, pytensor, python-louvain, PyWavelets, rmm-cu12, scikit-image, scikit-learn, scipy, scs, seaborn, shap, shapely, sklearn-pandas, soundfile, soxr, spacy, spanner-graph-notebook, stanio, statsmodels, stumpy, tables, tensorboard, tensorflow, tensorflow-datasets, tensorflow-hub, tensorflow-probability, tensorflow_decision_forests, tensorstore, thinc, tifffile, torchtune, torchvision, transformers, treelite, treescope, tsfresh, ucx-py-cu12, ucxx-cu12, umap-learn, wordcloud, xarray, xarray-einstats, xgboost, ydf, yellowbrick, yfinance\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJU_8-YSuEmZ",
        "outputId": "7231d915-4c2d-48e0-defd-b42c6b0e5803"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hi, AI Studio\n",
            "INFO:pipeline_from_tasks: Starting Complete E-commerce Recommendation System Pipeline...\n",
            "INFO:pipeline_from_tasks:5-Step Pipeline: Data  Process  Train  HPO  Final Model\n",
            "ClearML Task: created new task id=6e32aac636594e1d94d498c9bf8f8e9f\n",
            "CLEARML new package available: UPGRADE to v2.0.0 is recommended!\n",
            "Release Notes:\n",
            "### New Features\n",
            "\n",
            "- Clean up exception handeling in cleanup_service.py (#1387, thanks @PixelWelt!)\n",
            "- Add support for `clearml-task` command line options `--force-no-requirements`, `--skip-repo-detection` and `--skip-python-env-install`\n",
            "- Allow calling the same pipeline step multiple times with inputs that originate from tasks/controller\n",
            "- Add `Task.upload_artifact()` argument `sort_keys` to allow disabling sorting yaml/json keys when uploading artifacts\n",
            "- Add python annotations to all methods\n",
            "- Update `pyjwt` constraint version\n",
            "\n",
            "\n",
            "### Bug Fixes\n",
            "\n",
            "- Fix local file uploads without scheme (#1326, thanks @d-vignesh!)\n",
            "- Fix argument order mismatch in `PipelineController` (#1407, thanks @rashboldb!)\n",
            "- Fix `_logger` property might be `None` in Session (#1412, thanks @AH-Merii!)\n",
            "- Fix unhandled `None` value in project IDs when listing all datasets (#1413, thanks @AH-Merii!)\n",
            "- Fix typo in config exception string (#1418, thanks @AH-Merii!)\n",
            "- Fix experiments are created twice during HPO (#644)\n",
            "- Fix `clearml-task`-run HPO breaks up (#1151)\n",
            "- Fix oversized event reports cause subsequent events to be lost (#1316)\n",
            "- Fix downloading datasets with multiple parents might not work (#1398)\n",
            "- Fix GPU reporting fails to detect GPU when the `NVIDIA_VISIBLE_DEVICES` env var contains a directory reference\n",
            "- Fix `verify` configuration option for S3 storage (boto3) is not used when testing buckets\n",
            "- Fix `PipelineDecorator.component()` ignores `*args` and crashes with `**kwargs`\n",
            "- Fix Pipelines ran via `clearml-task` do not appear in the UI\n",
            "- Fix task log URL print for API v2.31 should show `\"/tasks/{}/output/log\"`\n",
            "- Fix `tqdm` upload/download reporting, remove warning\n",
            "- Fix pipeline from CLI with no args fails\n",
            "- Fix `pillow` constraint for Python<=3.7\n",
            "- Fix `requests` constraint for Python < 3.8\n",
            "\n",
            "2025-05-23 20:11:25.165086: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-05-23 20:11:25.167558: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2025-05-23 20:11:25.221670: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-05-23 20:11:26.550504: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "ClearML results page: https://app.clear.ml/projects/a5f546c1f3d948a193c9e206ca04b162/experiments/6e32aac636594e1d94d498c9bf8f8e9f/output/log\n",
            "ClearML pipeline page: https://app.clear.ml/pipelines/a5f546c1f3d948a193c9e206ca04b162/experiments/6e32aac636594e1d94d498c9bf8f8e9f\n",
            "INFO:pipeline_from_tasks:Set default execution queue to: pipeline\n",
            "INFO:pipeline_from_tasks:Adding Step 1: Dataset Creation\n",
            "2025-05-23 20:11:35,417 - clearml.util - WARNING - 27 task found when searching for `{'project_name': 'examples', 'task_name': 'Pipeline step 1 dataset artifact', 'include_archived': True, 'task_filter': {'status': ['created', 'queued', 'in_progress', 'published', 'stopped', 'completed', 'closed']}}`\n",
            "2025-05-23 20:11:35,418 - clearml.util - WARNING - Selected task `Pipeline step 1 dataset artifact` (id=6c12c89305ba4a558fc25ffbe37c1287)\n",
            "INFO:pipeline_from_tasks:Adding Step 2: Data Preprocessing\n",
            "2025-05-23 20:11:37,453 - clearml.util - WARNING - 12 task found when searching for `{'project_name': 'examples', 'task_name': 'Pipeline step 2 process dataset', 'include_archived': True, 'task_filter': {'status': ['created', 'queued', 'in_progress', 'published', 'stopped', 'completed', 'closed']}}`\n",
            "2025-05-23 20:11:37,454 - clearml.util - WARNING - Selected task `Pipeline step 2 process dataset` (id=cb8d133f414646ec8d1f755850230409)\n",
            "INFO:pipeline_from_tasks:Adding Step 3: Model Training\n",
            "2025-05-23 20:11:39,489 - clearml.util - WARNING - 9 task found when searching for `{'project_name': 'examples', 'task_name': 'Pipeline step 3 train model', 'include_archived': True, 'task_filter': {'status': ['created', 'queued', 'in_progress', 'published', 'stopped', 'completed', 'closed']}}`\n",
            "2025-05-23 20:11:39,489 - clearml.util - WARNING - Selected task `Pipeline step 3 train model` (id=719e41ed1ff942b79778bfac03e7e121)\n",
            "INFO:pipeline_from_tasks:Adding Step 4: Hyperparameter Optimization\n",
            "2025-05-23 20:11:41,533 - clearml.util - WARNING - 11 task found when searching for `{'project_name': 'examples', 'task_name': 'HPO: E-commerce Recommendation System', 'include_archived': True, 'task_filter': {'status': ['created', 'queued', 'in_progress', 'published', 'stopped', 'completed', 'closed']}}`\n",
            "2025-05-23 20:11:41,534 - clearml.util - WARNING - Selected task `HPO: E-commerce Recommendation System` (id=7b98e12fcab84fedbcadb378ac30d3c8)\n",
            "INFO:pipeline_from_tasks:Adding Step 5: Final Model Training\n",
            "2025-05-23 20:11:43,591 - clearml.util - WARNING - 2 task found when searching for `{'project_name': 'examples', 'task_name': 'Final E-commerce Model Training', 'include_archived': True, 'task_filter': {'status': ['created', 'queued', 'in_progress', 'published', 'stopped', 'completed', 'closed']}}`\n",
            "2025-05-23 20:11:43,591 - clearml.util - WARNING - Selected task `Final E-commerce Model Training` (id=497d1290593e4ed28eccec75d44b9b25)\n",
            "INFO:pipeline_from_tasks:============================================================\n",
            "INFO:pipeline_from_tasks:COMPLETE E-COMMERCE PIPELINE STRUCTURE\n",
            "INFO:pipeline_from_tasks:============================================================\n",
            "INFO:pipeline_from_tasks: Step 1: Dataset Creation\n",
            "INFO:pipeline_from_tasks:    Creates Amazon e-commerce sample dataset\n",
            "INFO:pipeline_from_tasks: Step 2: Data Preprocessing\n",
            "INFO:pipeline_from_tasks:    Cleans data, handles outliers, feature engineering\n",
            "INFO:pipeline_from_tasks: Step 3: Model Training\n",
            "INFO:pipeline_from_tasks:    Trains clustering + recommendation models\n",
            "INFO:pipeline_from_tasks: Step 4: Hyperparameter Optimization\n",
            "INFO:pipeline_from_tasks:    Finds best parameters using HPO\n",
            "INFO:pipeline_from_tasks: Step 5: Final Model Training\n",
            "INFO:pipeline_from_tasks:    Trains final model with optimized parameters\n",
            "INFO:pipeline_from_tasks:============================================================\n",
            "INFO:pipeline_from_tasks:Execution Queue: pipeline\n",
            "INFO:pipeline_from_tasks:============================================================\n",
            "INFO:pipeline_from_tasks: Starting complete 5-step pipeline execution...\n",
            "INFO:pipeline_from_tasks:This will take approximately 30-45 minutes to complete\n",
            "Launching the next 1 steps\n",
            "Launching step [step1_dataset]\n",
            "Launching step: step1_dataset\n",
            "Parameters:\n",
            "None\n",
            "Configurations:\n",
            "{}\n",
            "Overrides:\n",
            "{}\n",
            "Launching the next 1 steps\n",
            "Launching step [step2_preprocessing]\n",
            "Launching step: step2_preprocessing\n",
            "Parameters:\n",
            "{'General/dataset_task_id': '${step1_dataset.id}', 'General/test_size': 0.25, 'General/random_state': 42, 'General/remove_outliers': True, 'General/outlier_threshold': 3.0, 'General/feature_scaling': True, 'General/handle_missing_values': True}\n",
            "Configurations:\n",
            "{}\n",
            "Overrides:\n",
            "{}\n",
            "Launching the next 1 steps\n",
            "Launching step [step3_training]\n",
            "Launching step: step3_training\n",
            "Parameters:\n",
            "{'General/dataset_task_id': '${step2_preprocessing.id}', 'General/clustering_algorithm': 'kmeans', 'General/n_clusters_range': [2, 10], 'General/max_iter': 300, 'General/n_init': 10, 'General/optimize_clusters': True, 'General/train_recommendation': True, 'General/similarity_metric': 'cosine', 'General/min_interactions': 1}\n",
            "Configurations:\n",
            "{}\n",
            "Overrides:\n",
            "{}\n",
            "Launching the next 1 steps\n",
            "Launching step [step4_hpo]\n",
            "Launching step: step4_hpo\n",
            "Parameters:\n",
            "{'General/base_train_task_id': '${step3_training.id}', 'General/processed_dataset_id': '${step2_preprocessing.id}', 'General/num_trials': 5, 'General/time_limit_minutes': 25, 'General/run_as_service': False, 'General/test_queue': 'pipeline', 'General/n_clusters_max': 10, 'General/max_iter': 300, 'General/outlier_threshold': 3.0, 'General/min_interactions': 2, 'General/clustering_algorithm': 'kmeans', 'General/similarity_metric': 'cosine'}\n",
            "Configurations:\n",
            "{}\n",
            "Overrides:\n",
            "{}\n",
            "Launching the next 1 steps\n",
            "Launching step [step5_final_model]\n",
            "Launching step: step5_final_model\n",
            "Parameters:\n",
            "{'General/processed_dataset_id': '${step2_preprocessing.id}', 'General/hpo_task_id': '${step4_hpo.id}', 'General/test_queue': 'pipeline', 'General/n_clusters_range_max': 5, 'General/max_iter': 300, 'General/outlier_threshold': 3.0, 'General/min_interactions': 2, 'General/clustering_algorithm': 'kmeans', 'General/similarity_metric': 'cosine'}\n",
            "Configurations:\n",
            "{}\n",
            "Overrides:\n",
            "{}\n",
            "Launching the next 0 steps\n",
            "INFO:pipeline_from_tasks: Complete pipeline started successfully!\n",
            "INFO:pipeline_from_tasks: Monitor progress in ClearML UI\n",
            "INFO:pipeline_from_tasks: Pipeline Flow:\n",
            "INFO:pipeline_from_tasks:   step1_dataset  step2_preprocessing  step3_training\n",
            "INFO:pipeline_from_tasks:                                    \n",
            "INFO:pipeline_from_tasks:   step5_final_model  step4_hpo \n"
          ]
        }
      ]
    }
  ]
}
